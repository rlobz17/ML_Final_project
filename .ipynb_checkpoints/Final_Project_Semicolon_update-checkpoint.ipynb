{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagate(X, theta1, theta2):\n",
    "    m = X.shape[0]\n",
    "    \n",
    "    a1 = np.insert(X, 0, values=np.ones(m), axis=1)\n",
    "    z2 = a1 * theta1.T\n",
    "    a2 = np.insert(sigmoid(z2), 0, values=np.ones(m), axis=1)\n",
    "    z3 = a2 * theta2.T\n",
    "    h = sigmoid(z3)\n",
    "    \n",
    "    return a1, z2, a2, z3, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(params, input_size, hidden_size, num_labels, X, y, learning_rate):\n",
    "    m = X.shape[0]\n",
    "    X = np.matrix(X)\n",
    "    y = np.matrix(y)\n",
    "    \n",
    "    # reshape the parameter array into parameter matrices for each layer\n",
    "    theta1 = np.matrix(np.reshape(params[:hidden_size * (input_size + 1)], (hidden_size, (input_size + 1))))\n",
    "    theta2 = np.matrix(np.reshape(params[hidden_size * (input_size + 1):], (num_labels, (hidden_size + 1))))\n",
    "    \n",
    "    # run the feed-forward pass\n",
    "    a1, z2, a2, z3, h = forward_propagate(X, theta1, theta2)\n",
    "    \n",
    "    # compute the cost\n",
    "    J = 0\n",
    "    for i in range(m):\n",
    "        first_term = np.multiply(-y[i,:], np.log(h[i,:]))\n",
    "        second_term = np.multiply((1 - y[i,:]), np.log(1 - h[i,:]))\n",
    "        J += np.sum(first_term - second_term)\n",
    "    \n",
    "    J = J / m\n",
    "    \n",
    "    # add the cost regularization term\n",
    "    J += (float(learning_rate) / (2 * m)) * (np.sum(np.power(theta1[:,1:], 2)) + np.sum(np.power(theta2[:,1:], 2)))\n",
    "    \n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_gradient(z):\n",
    "    return np.multiply(sigmoid(z), (1 - sigmoid(z)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop(params, input_size, hidden_size, num_labels, X, y, learning_rate):\n",
    "    m = X.shape[0]\n",
    "    X = np.matrix(X)\n",
    "    y = np.matrix(y)\n",
    "    \n",
    "    # reshape the parameter array into parameter matrices for each layer\n",
    "    theta1 = np.matrix(np.reshape(params[:hidden_size * (input_size + 1)], (hidden_size, (input_size + 1))))\n",
    "    theta2 = np.matrix(np.reshape(params[hidden_size * (input_size + 1):], (num_labels, (hidden_size + 1))))\n",
    "    \n",
    "    # run the feed-forward pass\n",
    "    a1, z2, a2, z3, h = forward_propagate(X, theta1, theta2)\n",
    "    \n",
    "    # initializations\n",
    "    J = 0\n",
    "    delta1 = np.zeros(theta1.shape)  # (25, 401)\n",
    "    delta2 = np.zeros(theta2.shape)  # (10, 26)\n",
    "    \n",
    "    # compute the cost\n",
    "    for i in range(m):\n",
    "        first_term = np.multiply(-y[i,:], np.log(h[i,:]))\n",
    "        second_term = np.multiply((1 - y[i,:]), np.log(1 - h[i,:]))\n",
    "        J += np.sum(first_term - second_term)\n",
    "    \n",
    "    #print(J)\n",
    "    J = J / m\n",
    "    \n",
    "    # add the cost regularization term\n",
    "    J += (float(learning_rate) / (2 * m)) * (np.sum(np.power(theta1[:,1:], 2)) + np.sum(np.power(theta2[:,1:], 2)))\n",
    "    \n",
    "    # perform backpropagation\n",
    "    for t in range(m):\n",
    "        a1t = a1[t,:]  # (1, 401)\n",
    "        z2t = z2[t,:]  # (1, 25)\n",
    "        a2t = a2[t,:]  # (1, 26)\n",
    "        ht = h[t,:]  # (1, 10)\n",
    "        yt = y[t,:]  # (1, 10)\n",
    "        \n",
    "        d3t = ht - yt  # (1, 10)\n",
    "        \n",
    "        z2t = np.insert(z2t, 0, values=np.ones(1))  # (1, 26)\n",
    "        d2t = np.multiply((theta2.T * d3t.T).T, sigmoid_gradient(z2t))  # (1, 26)\n",
    "        \n",
    "        delta1 = delta1 + (d2t[:,1:]).T * a1t\n",
    "        delta2 = delta2 + d3t.T * a2t\n",
    "        \n",
    "    delta1 = delta1 / m\n",
    "    delta2 = delta2 / m\n",
    "    \n",
    "    # add the gradient regularization term\n",
    "    delta1[:,1:] = delta1[:,1:] + (theta1[:,1:] * learning_rate) / m\n",
    "    delta2[:,1:] = delta2[:,1:] + (theta2[:,1:] * learning_rate) / m\n",
    "    \n",
    "    # unravel the gradient matrices into a single array\n",
    "    grad = np.concatenate((np.ravel(delta1), np.ravel(delta2)))\n",
    "    \n",
    "    return J, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading helper data on path: ./Data/Helper/backGround_street.wav\n",
      "reading helper data on path: ./Data/Helper/backGround_noice.wav\n",
      "reading helper data on path: ./Data/Helper/backGround_nature.wav\n",
      "[new value of  16\n",
      "-new value of  34\n",
      "-new value of  35\n",
      "----new value of  62\n",
      "----new value of  65\n",
      "--------new value of  72\n",
      "---------new value of  77\n",
      "-----------------------------------------------------------------------new value of  82\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------new value of  85\n",
      "---------------------------------new value of  87\n",
      "--------------------------------new value of  88\n",
      "------------------------------------new value of  93\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------]\n",
      "[################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################]\n",
      "[---------------------------]\n",
      "[###########################]\n"
     ]
    }
   ],
   "source": [
    "# pre_initial setup\n",
    "import DataProvider\n",
    "prov = DataProvider.DataProvider()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list()\n",
    "y = list()\n",
    "trainVal = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "while prov.hasNext(True):\n",
    "    Xt, yt = prov.next(True)\n",
    "    for i in range(len(yt)):\n",
    "        if yt[i] == 1:\n",
    "            trainVal.append(i+1)\n",
    "            \n",
    "    X.append(Xt)\n",
    "    y.append(yt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4816, 1860), (4816, 5))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.nan_to_num(np.matrix(X))\n",
    "y = np.matrix(y)\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = list()\n",
    "y2 = list()\n",
    "actualVal = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "while prov.hasNext(False):\n",
    "    X2t, y2t = prov.next(False)\n",
    "    actualVal.append(y2t)\n",
    "    \n",
    "    k = np.zeros(5)\n",
    "    k[y2t - 1] = 1\n",
    "    \n",
    "    X2.append(X2t)\n",
    "    y2.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((27, 1860), (27, 5))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2 = np.nan_to_num(np.matrix(X2))\n",
    "y2 = np.matrix(y2)\n",
    "\n",
    "X2.shape, y2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 1861), (5, 3))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initial setup\n",
    "input_size = prov.returnSizeOfEverySpectogram()\n",
    "hidden_size = 2\n",
    "num_labels = 5\n",
    "learning_rate = 1\n",
    "epochs = 50\n",
    "\n",
    "# randomly initialize a parameter array of the size of the full network's parameters\n",
    "params = (np.random.random(size=hidden_size * (input_size + 1) + num_labels * (hidden_size + 1)) - 0.5) * 0.25\n",
    "#print(params.shape)\n",
    "#params = np.ones(hidden_size * (input_size + 1) + num_labels * (hidden_size + 1))\n",
    "\n",
    "# unravel the parameter array into parameter matrices for each layer\n",
    "theta1 = np.matrix(np.reshape(params[:hidden_size * (input_size + 1)], (hidden_size, (input_size + 1))))\n",
    "theta2 = np.matrix(np.reshape(params[hidden_size * (input_size + 1):], (num_labels, (hidden_size + 1))))\n",
    "\n",
    "theta1.shape, theta2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch N: 0 ---> succeeded\n",
      "epoch N: 1 ---> succeeded\n",
      "epoch N: 2 ---> succeeded\n",
      "epoch N: 3 ---> succeeded\n",
      "epoch N: 4 ---> succeeded\n",
      "epoch N: 5 ---> succeeded\n",
      "epoch N: 6 ---> succeeded\n",
      "epoch N: 7 ---> succeeded\n",
      "epoch N: 8 ---> succeeded\n",
      "epoch N: 9 ---> succeeded\n",
      "epoch N: 10 ---> succeeded\n",
      "epoch N: 11 ---> succeeded\n",
      "epoch N: 12 ---> succeeded\n",
      "epoch N: 13 ---> succeeded\n",
      "epoch N: 14 ---> succeeded\n",
      "epoch N: 15 ---> succeeded\n",
      "epoch N: 16 ---> succeeded\n",
      "epoch N: 17 ---> succeeded\n",
      "epoch N: 18 ---> succeeded\n",
      "epoch N: 19 ---> succeeded\n",
      "epoch N: 20 ---> succeeded\n",
      "epoch N: 21 ---> succeeded\n",
      "epoch N: 22 ---> succeeded\n",
      "epoch N: 23 ---> succeeded\n",
      "epoch N: 24 ---> succeeded\n",
      "epoch N: 25 ---> succeeded\n",
      "epoch N: 26 ---> succeeded\n",
      "epoch N: 27 ---> succeeded\n",
      "epoch N: 28 ---> succeeded\n",
      "epoch N: 29 ---> succeeded\n",
      "epoch N: 30 ---> succeeded\n",
      "epoch N: 31 ---> succeeded\n",
      "epoch N: 32 ---> succeeded\n",
      "epoch N: 33 ---> succeeded\n",
      "epoch N: 34 ---> succeeded\n",
      "epoch N: 35 ---> succeeded\n",
      "epoch N: 36 ---> succeeded\n",
      "epoch N: 37 ---> succeeded\n",
      "epoch N: 38 ---> succeeded\n",
      "epoch N: 39 ---> succeeded\n",
      "epoch N: 40 ---> succeeded\n",
      "epoch N: 41 ---> succeeded\n",
      "epoch N: 42 ---> succeeded\n",
      "epoch N: 43 ---> succeeded\n",
      "epoch N: 44 ---> succeeded\n",
      "epoch N: 45 ---> succeeded\n",
      "epoch N: 46 ---> succeeded\n",
      "epoch N: 47 ---> succeeded\n",
      "epoch N: 48 ---> succeeded\n",
      "epoch N: 49 ---> succeeded\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for index in range(len(X)):\n",
    "        Xt = X[index]\n",
    "        yt = y[index]\n",
    "        J, grad = backprop(params, input_size, hidden_size, num_labels, Xt, yt, learning_rate)\n",
    "        params -= grad\n",
    "        print(J)\n",
    "    print(\"epoch N:\",epoch,\"---> succeeded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.08211683e+01, -5.76953305e-09,  7.99580702e-09, ...,\n",
       "       -4.86180274e+00, -7.61829345e-03, -7.61829343e-03])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "testRes = []\n",
    "\n",
    "theta1 = np.matrix(np.reshape(params[:hidden_size * (input_size + 1)], (hidden_size, (input_size + 1))))\n",
    "theta2 = np.matrix(np.reshape(params[hidden_size * (input_size + 1):], (num_labels, (hidden_size + 1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.10429882 0.84297186 0.22559729 ... 0.         0.         0.        ]]\n",
      "[[0. 1. 0. 0. 0.]]\n",
      "[[0.99005416 0.00468744 0.00992435 0.00237115 0.00756192]]\n",
      "[[-1.17429471  0.07979877  1.50101852 ...  0.          0.\n",
      "   0.        ]]\n",
      "[[0. 0. 0. 0. 1.]]\n",
      "[[0.99005416 0.00468744 0.00992435 0.00237115 0.00756192]]\n",
      "[[-1.98431826 -0.13079834 -0.14884748 ...  0.          0.\n",
      "   0.        ]]\n",
      "[[0. 0. 0. 0. 1.]]\n",
      "[[0.99005416 0.00468744 0.00992435 0.00237115 0.00756192]]\n",
      "[[-0.57486361 -0.93417966 -0.88993984 ...  0.          0.\n",
      "   0.        ]]\n",
      "[[1. 0. 0. 0. 0.]]\n",
      "[[0.99005416 0.00468744 0.00992435 0.00237115 0.00756192]]\n",
      "[[-1.22655666 -0.6860289   1.25584924 ...  0.          0.\n",
      "   0.        ]]\n",
      "[[0. 0. 0. 0. 1.]]\n",
      "[[0.99005416 0.00468744 0.00992435 0.00237115 0.00756192]]\n",
      "[[-1.02249658 -0.98860562  0.24954413 ...  0.          0.\n",
      "   0.        ]]\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "[[0.99005416 0.00468744 0.00992435 0.00237115 0.00756192]]\n",
      "[[-0.49393836 -0.22859827 -2.26535726 ...  0.          0.\n",
      "   0.        ]]\n",
      "[[0. 0. 0. 0. 1.]]\n",
      "[[0.99005416 0.00468744 0.00992435 0.00237115 0.00756192]]\n",
      "[[ 1.20406222  1.04037201 -2.42626977 ...  0.          0.\n",
      "   0.        ]]\n",
      "[[1. 0. 0. 0. 0.]]\n",
      "[[0.99005416 0.00468744 0.00992435 0.00237115 0.00756192]]\n",
      "[[ 0.98056459  1.31355929 -0.28082082 ...  0.          0.\n",
      "   0.        ]]\n",
      "[[0. 1. 0. 0. 0.]]\n",
      "[[0.99005416 0.00468744 0.00992435 0.00237115 0.00756192]]\n",
      "[[-1.37008369 -1.07080722 -0.50416976 ...  0.          0.\n",
      "   0.        ]]\n",
      "[[1. 0. 0. 0. 0.]]\n",
      "[[0.99005416 0.00468744 0.00992435 0.00237115 0.00756192]]\n",
      "[[-0.35705537  0.0534385   0.33281484 ...  0.          0.\n",
      "   0.        ]]\n",
      "[[0. 0. 1. 0. 0.]]\n",
      "[[0.99005416 0.00468744 0.00992435 0.00237115 0.00756192]]\n",
      "[[ 1.2730372   1.48656142 -1.67923248 ...  0.          0.\n",
      "   0.        ]]\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "[[0.99005416 0.00468744 0.00992435 0.00237115 0.00756192]]\n",
      "[[-0.90114182 -1.05767345  0.42528278 ...  0.          0.\n",
      "   0.        ]]\n",
      "[[0. 0. 1. 0. 0.]]\n",
      "[[0.99005416 0.00468744 0.00992435 0.00237115 0.00756192]]\n",
      "[[-0.75684589 -1.46786237  0.58465326 ...  0.          0.\n",
      "   0.        ]]\n",
      "[[0. 0. 0. 0. 1.]]\n",
      "[[0.99005416 0.00468744 0.00992435 0.00237115 0.00756192]]\n",
      "[[ 1.29453325  1.59879565 -1.37217069 ...  0.          0.\n",
      "   0.        ]]\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "[[0.99005416 0.00468744 0.00992435 0.00237115 0.00756192]]\n",
      "[[-0.17493333 -1.35126626 -1.31088233 ...  0.          0.\n",
      "   0.        ]]\n",
      "[[0. 1. 0. 0. 0.]]\n",
      "[[0.99005416 0.00468744 0.00992435 0.00237115 0.00756192]]\n",
      "[[0.37254104 1.55413043 1.08072674 ... 0.         0.         0.        ]]\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "[[0.99005416 0.00468744 0.00992435 0.00237115 0.00756192]]\n",
      "[[0.51447493 0.26788151 0.41769469 ... 0.         0.         0.        ]]\n",
      "[[0. 1. 0. 0. 0.]]\n",
      "[[0.99005416 0.00468744 0.00992435 0.00237115 0.00756192]]\n",
      "[[-0.88950861 -1.8961246   0.68681097 ...  0.          0.\n",
      "   0.        ]]\n",
      "[[1. 0. 0. 0. 0.]]\n",
      "[[0.99005416 0.00468744 0.00992435 0.00237115 0.00756192]]\n",
      "[[-1.34450138 -1.4023633   0.5986706  ...  0.          0.\n",
      "   0.        ]]\n",
      "[[0. 0. 1. 0. 0.]]\n",
      "[[0.99005416 0.00468744 0.00992435 0.00237115 0.00756192]]\n",
      "[[-2.14847565 -1.53823066  1.37742937 ...  0.          0.\n",
      "   0.        ]]\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "[[0.99005416 0.00468744 0.00992435 0.00237115 0.00756192]]\n",
      "[[1.35759592 1.67347109 0.23344445 ... 0.         0.         0.        ]]\n",
      "[[0. 1. 0. 0. 0.]]\n",
      "[[0.99005416 0.00468744 0.00992435 0.00237115 0.00756192]]\n",
      "[[-1.55858946 -0.62034273  0.47459641 ...  0.          0.\n",
      "   0.        ]]\n",
      "[[0. 0. 1. 0. 0.]]\n",
      "[[0.99005416 0.00468744 0.00992435 0.00237115 0.00756192]]\n",
      "[[-0.65791416 -1.04974508 -0.69659382 ...  0.          0.\n",
      "   0.        ]]\n",
      "[[0. 0. 0. 0. 1.]]\n",
      "[[0.99005416 0.00468744 0.00992435 0.00237115 0.00756192]]\n",
      "[[-0.41846055 -0.03699739 -0.59187782 ...  0.          0.\n",
      "   0.        ]]\n",
      "[[0. 0. 0. 0. 1.]]\n",
      "[[0.99005416 0.00468744 0.00992435 0.00237115 0.00756192]]\n",
      "[[ 1.04318202  0.24405035 -0.93912631 ...  0.          0.\n",
      "   0.        ]]\n",
      "[[1. 0. 0. 0. 0.]]\n",
      "[[0.99005416 0.00468744 0.00992435 0.00237115 0.00756192]]\n",
      "[[-0.71916133 -1.59866285  0.6566276  ...  0.          0.\n",
      "   0.        ]]\n",
      "[[0. 0. 1. 0. 0.]]\n",
      "[[0.99005416 0.00468744 0.00992435 0.00237115 0.00756192]]\n"
     ]
    }
   ],
   "source": [
    "for index in range(len(X2)):\n",
    "    X2t = X2[index]\n",
    "    y2t = y2[index]\n",
    "    print(X2t)\n",
    "    print(y2t)\n",
    "    a1, z2, a2, z3, h = forward_propagate(X2t, theta1, theta2)\n",
    "    print(h)\n",
    "    testRes.append((h, y2t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(matrix([[0.99005416, 0.00468744, 0.00992435, 0.00237115, 0.00756192]]),\n",
       "  matrix([[0., 1., 0., 0., 0.]])),\n",
       " (matrix([[0.99005416, 0.00468744, 0.00992435, 0.00237115, 0.00756192]]),\n",
       "  matrix([[0., 0., 0., 0., 1.]])),\n",
       " (matrix([[0.99005416, 0.00468744, 0.00992435, 0.00237115, 0.00756192]]),\n",
       "  matrix([[0., 0., 0., 0., 1.]])),\n",
       " (matrix([[0.99005416, 0.00468744, 0.00992435, 0.00237115, 0.00756192]]),\n",
       "  matrix([[1., 0., 0., 0., 0.]])),\n",
       " (matrix([[0.99005416, 0.00468744, 0.00992435, 0.00237115, 0.00756192]]),\n",
       "  matrix([[0., 0., 0., 0., 1.]])),\n",
       " (matrix([[0.99005416, 0.00468744, 0.00992435, 0.00237115, 0.00756192]]),\n",
       "  matrix([[0., 0., 0., 1., 0.]])),\n",
       " (matrix([[0.99005416, 0.00468744, 0.00992435, 0.00237115, 0.00756192]]),\n",
       "  matrix([[0., 0., 0., 0., 1.]])),\n",
       " (matrix([[0.99005416, 0.00468744, 0.00992435, 0.00237115, 0.00756192]]),\n",
       "  matrix([[1., 0., 0., 0., 0.]])),\n",
       " (matrix([[0.99005416, 0.00468744, 0.00992435, 0.00237115, 0.00756192]]),\n",
       "  matrix([[0., 1., 0., 0., 0.]])),\n",
       " (matrix([[0.99005416, 0.00468744, 0.00992435, 0.00237115, 0.00756192]]),\n",
       "  matrix([[1., 0., 0., 0., 0.]])),\n",
       " (matrix([[0.99005416, 0.00468744, 0.00992435, 0.00237115, 0.00756192]]),\n",
       "  matrix([[0., 0., 1., 0., 0.]])),\n",
       " (matrix([[0.99005416, 0.00468744, 0.00992435, 0.00237115, 0.00756192]]),\n",
       "  matrix([[0., 0., 0., 1., 0.]])),\n",
       " (matrix([[0.99005416, 0.00468744, 0.00992435, 0.00237115, 0.00756192]]),\n",
       "  matrix([[0., 0., 1., 0., 0.]])),\n",
       " (matrix([[0.99005416, 0.00468744, 0.00992435, 0.00237115, 0.00756192]]),\n",
       "  matrix([[0., 0., 0., 0., 1.]])),\n",
       " (matrix([[0.99005416, 0.00468744, 0.00992435, 0.00237115, 0.00756192]]),\n",
       "  matrix([[0., 0., 0., 1., 0.]])),\n",
       " (matrix([[0.99005416, 0.00468744, 0.00992435, 0.00237115, 0.00756192]]),\n",
       "  matrix([[0., 1., 0., 0., 0.]])),\n",
       " (matrix([[0.99005416, 0.00468744, 0.00992435, 0.00237115, 0.00756192]]),\n",
       "  matrix([[0., 0., 0., 1., 0.]])),\n",
       " (matrix([[0.99005416, 0.00468744, 0.00992435, 0.00237115, 0.00756192]]),\n",
       "  matrix([[0., 1., 0., 0., 0.]])),\n",
       " (matrix([[0.99005416, 0.00468744, 0.00992435, 0.00237115, 0.00756192]]),\n",
       "  matrix([[1., 0., 0., 0., 0.]])),\n",
       " (matrix([[0.99005416, 0.00468744, 0.00992435, 0.00237115, 0.00756192]]),\n",
       "  matrix([[0., 0., 1., 0., 0.]])),\n",
       " (matrix([[0.99005416, 0.00468744, 0.00992435, 0.00237115, 0.00756192]]),\n",
       "  matrix([[0., 0., 0., 1., 0.]])),\n",
       " (matrix([[0.99005416, 0.00468744, 0.00992435, 0.00237115, 0.00756192]]),\n",
       "  matrix([[0., 1., 0., 0., 0.]])),\n",
       " (matrix([[0.99005416, 0.00468744, 0.00992435, 0.00237115, 0.00756192]]),\n",
       "  matrix([[0., 0., 1., 0., 0.]])),\n",
       " (matrix([[0.99005416, 0.00468744, 0.00992435, 0.00237115, 0.00756192]]),\n",
       "  matrix([[0., 0., 0., 0., 1.]])),\n",
       " (matrix([[0.99005416, 0.00468744, 0.00992435, 0.00237115, 0.00756192]]),\n",
       "  matrix([[0., 0., 0., 0., 1.]])),\n",
       " (matrix([[0.99005416, 0.00468744, 0.00992435, 0.00237115, 0.00756192]]),\n",
       "  matrix([[1., 0., 0., 0., 0.]])),\n",
       " (matrix([[0.99005416, 0.00468744, 0.00992435, 0.00237115, 0.00756192]]),\n",
       "  matrix([[0., 0., 1., 0., 0.]]))]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testRes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
